# 项目报告：西瓜数据集上的 SVM 与 AdaBoost 分析

**日期：** 2025年12月16日  
**数据集：** 西瓜质量分类（17个样本，2个特征）

---

## 摘要

本报告对西瓜质量二分类数据集进行系统分析，比较两类经典方法：
1. **支持向量机（SVM）**：线性核与高斯核（RBF）
2. **AdaBoost 集成学习**：以不剪枝决策树为基学习器

两种方法在训练集上均取得了很好的表现，但其决策边界形态与学习机制存在显著差异。

---

## 数据集描述

- **样本量：** 17
- **特征：**
  - 密度（Density）
  - 含糖量（Sugar Content）
- **目标：** 二分类（好瓜/坏瓜）
  - 正类（好瓜）：8
  - 负类（坏瓜）：9
- **预处理：** 使用 StandardScaler 标准化特征

---

## 任务一：不同核函数的 SVM

### 方法

基于 LIBSVM（通过 scikit-learn）训练两种 SVM：
1. **线性核 SVM**：学习线性决策边界
2. **高斯核（RBF）SVM**：学习非线性决策边界

**主要超参数：**
- C（正则化系数）：1.0
- gamma（RBF 核系数）：'scale'

### 结果

#### 支持向量分析

| 指标 | 线性核 | 高斯核（RBF） |
|------|--------|----------------|
| 支持向量总数 | 13 | 14 |
| 类别0支持向量 | 7 | 7 |
| 类别1支持向量 | 6 | 7 |
| 占训练样本比例 | 76.5% | 82.4% |
| 共同支持向量数 | 10 |

### 关键发现：支持向量对比

#### 1. 支持向量数量

- **线性核（13个）**：
  - 支持向量略少，模型更为简洁
  - 边界形态更简单，效率更高

- **RBF 核（14个）**：
  - 支持向量更多，模型更灵活
  - 能捕获复杂的非线性关系

#### 2. 支持向量分布

两种核函数在两类样本上支持向量分布较为均衡，说明数据在边界附近存在重叠，需要更精细的边界刻画。

#### 3. 共同支持向量

两种模型共同识别了 10 个关键样本为支持向量，表明这些样本对分类间隔的定义至关重要。

#### 4. 核函数差异

**线性核优势：**
- 产生直线型分隔超平面
- 对近线性可分数据泛化更好
- 计算复杂度较低、不易过拟合
- 决策边界更易解释

**RBF 核优势：**
- 决策边界灵活、可非线性分割
- 适合复杂、非线性数据
- 对训练数据拟合更紧密（需注意正则化以防过拟合）

#### 5. 结果可视化

![不同核函数的SVM对比](results/svm_comparison.png)
从上图可见：
- 线性核边界为直线，RBF 核边界呈曲线，紧贴样本簇形态
- 两者均展示明确的间隔区域（与最近样本的距离）
- 支持向量（绿色圆圈）位于或接近间隔边界

### 解读

支持向量比例较高（>75%）意味着：
1. 数据集在清晰间隔意义下并非线性可分；
2. 样本分布紧密且存在显著重叠；
3. 两类核函数都需依赖大量边界样本来确定最优分割；
4. 小样本量（17）导致大多数点都对边界有实质影响。

---

## 任务二：AdaBoost 集成学习

### 方法

实现 AdaBoost.M1，使用不剪枝决策树（`max_depth=None`）作为基学习器：
- **基学习器数量：** 最多 50 个
- **权重更新：** 基于分类错误的指数加权
- **可视化：** 比较集成规模 1、3、5、11 的分类边界

### 结果

#### 训练表现

| 集成规模 | 训练准确率 | 改进 |
|----------|------------|------|
| 1 | 100.00% | - |
| 3 | 100.00% | +0.00% |
| 5 | 100.00% | +0.00% |
| 11 | 100.00% | +0.00% |
| 21 | 100.00% | +0.00% |
| 31 | 100.00% | +0.00% |
| 50 | 100.00% | +0.00% |

#### 基学习器分析

所有基学习器训练误差均为 0（error = 0.0000）：
- **权重 α** 均较大（约 α ≈ 11.5129）
- **单个学习器** 即达到 100% 训练准确率
- 随后学习器继续保持一致决策，无需额外改进

### 集成规模对比

#### 1. 单基学习器（n=1）

- 已达到完美分类
- 不剪枝决策树可完全拟合小训练集
- 决策边界复杂且细致

#### 2. 小型集成（n=3）

- 维持完美准确率
- 边界稳定，提供冗余与一致性

#### 3. 中等集成（n=5）

- 持续完美表现
- 分类区域更平滑，边界更清晰

#### 4. 大型集成（n=11）

- 继续完美表现
- 决策边界最为细致，预测置信度最高

#### 5. 总结
- 由于给定的数据集规模太小，集成学习没有展现出应有的作用。可以考虑换用规模更大的数据集进行分类。

### 结果可视化
![不同学习器的表现](results/adaboost_individual_learners.png)
![集成学习表现](results/adaboost_comparison.png)
由上图可知：

#### 决策边界演化

1. **单学习器：** 边界有效但可能略显不规则；核心区域置信度高。
2. **多学习器：** 随集成增长边界更平滑、过渡区更明确、颜色更饱满（置信度更高）。

#### 个体学习器

每个基学习器贡献：
- **权重（α）：** 约 11.5129（对应完美分类）
- **边界形态：** 各学习器模式相近，互相强化一致决策

### 解读

首个学习器即完美分类的现象表明：

1. **数据特性：**
   - 样本量小（17）
   - 标准化后类间可分性较强
   - 不剪枝树具备“记忆”训练集的能力

2. **AdaBoost 行为：**
   - 当基学习器误差为 0 时，α 极大
   - 后续学习器权重调整空间很小
   - 集成对训练集形成高度一致的判决

3. **实践启示：**
   - 完美训练准确率并不保证泛化性能
   - 集成有助于稳定与一致性，但需防过拟合
   - 在小数据集上应结合交叉验证评估模型可靠性

---

## 方法对比：SVM vs AdaBoost

### 模型复杂度

| 方面 | SVM | AdaBoost |
|------|-----|----------|
| **决策边界** | 连续、基于间隔 | 分段、基于树划分 |
| **可解释性** | 中等（支持向量） | 较低（多树集成） |
| **复杂度控制** | C、gamma | 学习器数量、树深度 |
| **关键样本** | 13-14 个支持向量 | 所有样本经迭代参与 |

### 性能特征

**SVM：**
- 关注边界样本（支持向量）
- 边界平滑，正则化良好
- 泛化能力较强，理论有保证（最大间隔）

**AdaBoost：**
- 迭代使用全部训练样本
- 可获得极高训练准确率
- 多弱学习器组合，适应难分样本

### 场景建议

**适合选择 SVM 的场景：**
- 需要可解释的关键样本（支持向量）
- 期望平滑边界与较强泛化
- 对过拟合有顾虑
- 数据近线性可分

**适合选择 AdaBoost 的场景：**
- 追求高训练精度
- 数据存在复杂非线性模式
- 需要集成带来的稳健性
- 可接受较高计算开销

---

## 结论

### 任务一：SVM 核函数对比

1. **支持向量差异：**
   - 线性核：13 个（76.5%），边界更简洁
   - RBF 核：14 个（82.4%），边界更灵活
   - 共同支持向量 10 个，反映边界的稳定性

2. **核函数选择：**
   - 两者均适用于该数据集
   - 线性核更简洁、泛化更优；RBF 核适合非线性更强的场景

3. **数据洞察：**
   - 支持向量比例高表明类别分割具有挑战性
   - 样本分布接近且重叠，需更精细的边界

### 任务二：AdaBoost 集成分析

1. **集成规模影响：**
   - 单树已达完美训练精度；更多学习器提升稳定与置信
   - 前期增加学习器的边际收益有限

2. **边界演化：**
   - 集成增大使边界更平滑、过渡区更明确

3. **基学习器贡献：**
   - 所有学习器权重均高（α ≈ 11.51），模式一致、互相强化

### 总体建议

针对本西瓜数据集：
1. **线性核 SVM** 在性能与泛化之间取得较好平衡；
2. **AdaBoost** 训练表现极佳，但需谨慎防止过拟合；
3. **交叉验证** 对泛化评估至关重要；
4. **特征工程** 可进一步提升可分性、降低对支持向量的依赖。

---

## 技术实现

### 生成文件

1. `svm_analysis.py` —— 线性与 RBF 核的 SVM 实现与分析
2. `adaboost_analysis.py` —— 自实现 AdaBoost（不剪枝决策树为基学习器）
3. `main.py` —— 统一入口，运行全部分析
4. `requirements.txt` —— 项目依赖
5. `README.md` —— 项目说明

### 产出可视化

1. `results/svm_comparison.png` —— SVM 两种核的并排对比
2. `results/adaboost_comparison.png` —— 不同集成规模的边界对比
3. `results/adaboost_individual_learners.png` —— 前 4 个基学习器的边界


## 参考文献

- LIBSVM: https://www.csie.ntu.edu.tw/~cjlin/libsvm/
- Freund, Y., & Schapire, R. E. (1997). A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting
- Cortes, C., & Vapnik, V. (1995). Support-vector networks
- Scikit-learn: Machine Learning in Python

---

**报告结束**
